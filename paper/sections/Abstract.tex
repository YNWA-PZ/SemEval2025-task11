\begin{abstract}
    This paper explores multilingual emotion classification across binary classification, intensity estimation, and cross-lingual detection tasks. To address linguistic variability and limited annotated data, we evaluate various deep learning approaches, including transformer-based embeddings and traditional classifiers. After extensive experimentation, language-specific embedding models were selected as the final approach, given their superior ability to capture linguistic and cultural nuances. Experiments on high- and low-resource languages demonstrate that this method significantly improves performance, achieving competitive macro-average F1 scores. Notably, in languages such as Tigrinya and Kinyarwanda for cross-lingual detection task, our approach achieved a second-place ranking, driven by the incorporation of advanced preprocessing techniques. Despite these advances, challenges remain due to limited annotated data in underrepresented languages and the complexity of nuanced emotional expressions. The study highlights the need for robust, language-aware emotion recognition systems and emphasizes future directions, including expanding multilingual datasets and refining models.
\end{abstract}