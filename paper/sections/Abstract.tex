\begin{abstract}
This paper presents a comprehensive study on multilingual emotion classification, aimed at advancing the detection and analysis of emotions in textual data across diverse languages. The research is structured into three distinct tracks: binary emotion classification, intensity estimation, and cross-lingual emotion detection. To address challenges associated with linguistic variability and limited annotated data, we employ a combination of deep learning techniques, including Long Short-Term Memory networks, transformer-based embeddings fine-tuned via low-rank adaptation, and classifiers such as SVMs\footnote{Support Vector Machines} and XGBoost. Extensive experiments conducted on datasets covering both high and low resource languages demonstrate that innovative preprocessing and domain adaptation strategies significantly enhance model performance, as evidenced by competitive macro-average F1 scores. Despite these promising results, the study acknowledges limitations arising from the scarcity of annotated data in underrepresented languages and the inherent complexity of capturing nuanced emotional expressions. The findings underscore the importance of developing robust, language-aware emotion recognition systems and suggest that future research should focus on expanding multilingual datasets, refining model architectures, and exploring zero-shot learning techniques.
\end{abstract}